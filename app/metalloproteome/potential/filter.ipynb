{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SwissProt import FeatureTable\n",
    "\n",
    "swiss_file_path = Path(\"~/database/uniprot/swiss/\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22447"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_evid = pd.read_table(\"../analysis/no_evidence_pred_mbps.tsv\")\n",
    "posi_to_resi_species = dict()\n",
    "for _, row in df_no_evid.iterrows():\n",
    "    posi_to_resi_species[(row['seq_id'], row['resi_seq_posi_1'])] = (row['resi_1'], row['species'])\n",
    "    posi_to_resi_species[(row['seq_id'], row['resi_seq_posi_2'])] = (row['resi_2'], row['species'])\n",
    "\n",
    "records = []\n",
    "for p, r in posi_to_resi_species.items():\n",
    "    records.append({\n",
    "        \"seq_id\": p[0],\n",
    "        \"species\": r[1],\n",
    "        \"resi_seq_num\": p[1] + 1,\n",
    "        \"resi\": r[0],\n",
    "    })\n",
    "df_no_evid_resi = pd.DataFrame(records)\n",
    "len(df_no_evid_resi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get anno info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SwissProt\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def gen_swiss_record(source):\n",
    "    swiss_records = SwissProt.parse(source)\n",
    "    for swiss_record in swiss_records:\n",
    "        # Convert the SwissProt record to a SeqRecord\n",
    "        record = SeqRecord(\n",
    "            Seq(swiss_record.sequence),\n",
    "            id=swiss_record.accessions[0],\n",
    "            name=swiss_record.entry_name,\n",
    "            description=swiss_record.description,\n",
    "            features=swiss_record.features,\n",
    "        )\n",
    "        for cross_reference in swiss_record.cross_references:\n",
    "            if len(cross_reference) < 2:\n",
    "                continue\n",
    "            database, accession = cross_reference[:2]\n",
    "            description = cross_reference[2] if len(cross_reference) >= 3 else \"\"\n",
    "            \n",
    "            dbxref = f\"{database}; {accession}; {description}\"\n",
    "            if dbxref not in record.dbxrefs:\n",
    "                record.dbxrefs.append(dbxref)\n",
    "        yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_types = {\n",
    "    \"ACT_SITE\",\n",
    "    \"BINDING\",\n",
    "    \"CBAROHYD\",\n",
    "    \"CA_BIND\",\n",
    "    \"CROSSLNK\",\n",
    "    \"DISULFID\",\n",
    "    \"DNA_BIND\",\n",
    "    \"LIPID\",\n",
    "    \"METAL\",\n",
    "    \"MOD_RES\",\n",
    "    \"NP_BIND\",\n",
    "    \"ZN_FING\",\n",
    "}\n",
    "\n",
    "def annotate(\n",
    "    swiss_file: str,\n",
    "    target_uniprots: set,\n",
    ") -> pd.DataFrame:\n",
    "    records = []\n",
    "    for r in gen_swiss_record(swiss_file):\n",
    "        r: SeqRecord\n",
    "        uniprot = r.id\n",
    "        \n",
    "        if uniprot not in target_uniprots: continue\n",
    "        \n",
    "        for f in r.features:\n",
    "            f: FeatureTable\n",
    "            feat_type = f.type\n",
    "            \n",
    "            if feat_type not in anno_types: continue\n",
    "            try: note = f.qualifiers['note']\n",
    "            except: note = \" \"\n",
    "            try: locations = list(f.location)\n",
    "            except: continue\n",
    "            \n",
    "            for posi in locations:\n",
    "                try:\n",
    "                    records.append({\n",
    "                        \"seq_id\": r.id,\n",
    "                        \"resi_seq_num\": posi + 1,\n",
    "                        \"resi\": r.seq[posi],\n",
    "                        \"anno_type\": feat_type,\n",
    "                        \"anno_note\": note,\n",
    "                    })\n",
    "                except IndexError:\n",
    "                    continue\n",
    "    return pd.DataFrame(records)    \n",
    "\n",
    "def get_family(\n",
    "    swiss_file: str,\n",
    "    target_uniprots: set,\n",
    ") -> pd.DataFrame:\n",
    "    records = []\n",
    "    \n",
    "    for r in gen_swiss_record(swiss_file):\n",
    "        r: SeqRecord\n",
    "        uniprot = r.id\n",
    "        \n",
    "        if uniprot not in target_uniprots: continue\n",
    "        \n",
    "        pfam_info = (\"\", \"\")\n",
    "        supfam_info = (\"\", \"\")\n",
    "        for dbxref in r.dbxrefs:\n",
    "            database, id, desc = dbxref.split(\"; \")\n",
    "            if database == \"Pfam\": pfam_info = tuple((id, desc))\n",
    "            if database == \"SUPFAM\": supfam_info = tuple((id, desc))\n",
    "        pfam_id, pfam_desc = pfam_info\n",
    "        supfam_id, supfam_desc = supfam_info\n",
    "        \n",
    "        records.append({\n",
    "            \"seq_id\": uniprot,\n",
    "            \"pfam_id\": pfam_id,\n",
    "            \"pfam_desc\": pfam_desc,\n",
    "            \"supfam_id\": supfam_id,\n",
    "            \"supfam_desc\": supfam_desc\n",
    "        })\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9039/420115511.py:2: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for species, df_sp in df_no_evid_resi.groupby(['species']):\n"
     ]
    }
   ],
   "source": [
    "record_dfs = []\n",
    "for species, df_sp in df_no_evid_resi.groupby(['species']):\n",
    "    swiss_file = swiss_file_path / f\"{species}.txt\"\n",
    "    uniprots = set(df_sp['seq_id'])\n",
    "\n",
    "    record_dfs.append(annotate(swiss_file, uniprots))\n",
    "df_anno = pd.concat(record_dfs)\n",
    "df = pd.merge(df_no_evid_resi, df_anno, on=[\"seq_id\", \"resi_seq_num\", \"resi\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there may be other annos for pred residues, such as heme, ssbond, etc\n",
    "anno_seqs = set(df[df['anno_type'].notna()]['seq_id'])\n",
    "df_filtered = df_no_evid[df_no_evid['seq_id'].map(lambda x: x not in anno_seqs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get filtered result (with family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9039/234369109.py:2: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for species, df_sp in df_filtered.groupby(['species']):\n"
     ]
    }
   ],
   "source": [
    "record_dfs = []\n",
    "for species, df_sp in df_filtered.groupby(['species']):\n",
    "    swiss_file = swiss_file_path / f\"{species}.txt\"\n",
    "    uniprots = set(df_sp['seq_id'])\n",
    "\n",
    "    record_dfs.append(get_family(swiss_file, uniprots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(record_dfs).to_csv(\"potential_mbps_family.tsv\", sep=\"\\t\", index=None)\n",
    "df_filtered.to_csv(\"potential_mbps.tsv\", sep=\"\\t\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
