{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB.NeighborSearch import NeighborSearch\n",
    "from Bio.PDB.Atom import Atom\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sites located at the interface in test dataset (anno)\n",
    "df_anno = pd.read_table(f\"{PROJECT_DIR}/dataset/transform/test_metalnet.tsv\")\n",
    "df = pd.read_table(f\"{PROJECT_DIR}/dataset/collect/analysis/sites_interface_multi_num.tsv\")\n",
    "inter_sites = set(zip(df['pdb'], df['metal_chain'], df['metal_pdb_seq_num']))\n",
    "df_anno = df_anno[df_anno.apply(lambda row: (row['pdb'], row['metal_chain'], row['metal_pdb_seq_num']) in inter_sites, axis=1)]\n",
    "del df\n",
    "\n",
    "## predicted as true in test dataset\n",
    "df_pred = pd.read_table(\"../../pred_pairs.tsv\")\n",
    "df_pred = df_pred[df_pred['filter_by_graph'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many true residues on interface are successfully predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_residues = set(zip(df_anno['seq_id'], df_anno['resi_domain_posi']))\n",
    "pred_residues = set()\n",
    "for _, row in df_pred.iterrows():\n",
    "    pred_residues.add((row['seq_id'], row['resi_seq_posi_1']))\n",
    "    pred_residues.add((row['seq_id'], row['resi_seq_posi_2']))\n",
    "intersection = pred_residues & true_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metal sites located at interface:  24\n",
      "Residues located at interface: 15  / 67 (predicted / true)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('3a6v_B', 52),\n",
       " ('3a6v_B', 56),\n",
       " ('5gox_A', 100),\n",
       " ('5gox_A', 103),\n",
       " ('6hbe_C', 79),\n",
       " ('6hbe_C', 266),\n",
       " ('6j27_C', 117),\n",
       " ('6j27_C', 120),\n",
       " ('6sev_A', 24),\n",
       " ('6sev_A', 51),\n",
       " ('6sev_A', 55),\n",
       " ('7ukh_D', 104),\n",
       " ('7ukh_D', 110),\n",
       " ('7ukh_D', 131),\n",
       " ('7ukh_D', 132)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of metal sites located at interface: \", len(set(zip(df_anno['pdb'], df_anno['metal_chain'], df_anno['metal_pdb_seq_num']))))\n",
    "print(f\"Residues located at interface: {len(intersection)}  / {len(true_residues)} (predicted / true)\", )\n",
    "intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many predicted sites can be modeled on interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19122/1438827057.py:2: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_table(\"~/database/pdb/homomer/homomer_four_species.csv\")\n"
     ]
    }
   ],
   "source": [
    "## proteins with homomer (modeled, four species, from 'An atlas of protein homo-oligomerization across domains of life')\n",
    "df = pd.read_table(\"~/database/pdb/homomer/homomer_four_species.csv\")\n",
    "sp_abbr = {'hs': 'human', 'sc': 'yeast', 'ec': 'ecoli', 'pf': 'pfuri'}\n",
    "df['species'] = df['org'].map(lambda x: sp_abbr[x])\n",
    "uniprot_to_species = dict(zip(df['code_sub'], df['species']))\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pdb to uniprot\n",
    "df = pd.read_table(\"~/database/uniprot/idmapping/pdb2uniprot.csv\")\n",
    "pdb_to_uniprot = dict(zip(zip(df['pdb'], df['chain']), df['uniprot']))\n",
    "extra = {\n",
    "    ('8hmq', 'B'): 'P14618',\n",
    "    ('8ba5', 'A'): 'Q9H3E2',\n",
    "}\n",
    "pdb_to_uniprot.update(extra) # add human proteins in test_pred (no yeast, ecoli, pfuri proteins found)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_plddt(\n",
    "    id: str,\n",
    "    pdb_file: str\n",
    "):\n",
    "    residues = PDBParser(QUIET=True).get_structure(id, pdb_file).get_residues()\n",
    "    plddts = []\n",
    "    for r in residues:\n",
    "        ca: Atom = r['CA']\n",
    "        plddt = ca.get_bfactor()\n",
    "        plddts.append(plddt)\n",
    "    return np.average(plddts)\n",
    "\n",
    "path = \"~/database/pdb/species\"\n",
    "def get_af2_pdb(\n",
    "    uniprot: str,\n",
    "    species: str,\n",
    "):\n",
    "    pdb_file_path = os.path.join(path, f\"{species}_af2\")\n",
    "    pdb_files = os.popen(f\"find {pdb_file_path} -name *{uniprot}*\").readlines()\n",
    "    pdb_files = [os.path.join(pdb_file_path, i.strip()) for i in pdb_files]\n",
    "    return pdb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predicted as true in test dataset, and has homomers\n",
    "records = []\n",
    "for _, row in df_pred.iterrows():\n",
    "    seq_id = row['seq_id']\n",
    "    pdb, chain = seq_id.split(\"_\") # no split domains\n",
    "    if (pdb, chain) in pdb_to_uniprot.keys():\n",
    "        uniprot = pdb_to_uniprot[(pdb, chain)]\n",
    "        if uniprot in uniprot_to_species.keys():\n",
    "            sp = uniprot_to_species[uniprot]\n",
    "            pdb_files = get_af2_pdb(uniprot, sp)\n",
    "            assert len(pdb_files) == 1 # no fragments\n",
    "            pdb_file = pdb_files[0]\n",
    "            avg_plddt = calc_avg_plddt(row['seq_id'], pdb_file)\n",
    "            records.append({\n",
    "                **row,\n",
    "                \"uniprot\": uniprot,\n",
    "                \"species\": sp,\n",
    "                \"avg_plddt\": avg_plddt,\n",
    "            })\n",
    "df_pred_with_homomers = pd.DataFrame(records)\n",
    "del records\n",
    "\n",
    "## labeled as true interface sites, and has homomers\n",
    "records = []\n",
    "for _, row in df_anno.iterrows():\n",
    "    assert row['domain'] == \" \"\n",
    "    pdb, chain = row['pdb'], row['metal_chain']\n",
    "    if (pdb, chain) in pdb_to_uniprot.keys():\n",
    "        uniprot = pdb_to_uniprot[(pdb, chain)]\n",
    "        if uniprot in uniprot_to_species.keys():\n",
    "            sp = uniprot_to_species[uniprot]\n",
    "            records.append({\n",
    "                **row,\n",
    "                \"uniprot\": uniprot,\n",
    "                \"species\": sp,\n",
    "            })\n",
    "df_anno_with_homomers = pd.DataFrame(records)\n",
    "len(df_anno_with_homomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homomer_protein(uniprot):\n",
    "    path = \"~/database/pdb/homomer/AF_dimer_models_full_length_relaxed\" # NOTE: we consider dimer here\n",
    "    file = os.popen(f\"ls {path}/{uniprot}*\").readline().strip()\n",
    "    return file\n",
    "\n",
    "def get_inter_residues(\n",
    "    uniprot: str, \n",
    "    pdb_file: str,\n",
    "    inter_threshold: float = 8.,\n",
    "    neighbor_num_threshold: int = 2, \n",
    "):\n",
    "    atoms = []\n",
    "    residues = list(PDBParser(QUIET=True).get_structure(uniprot, pdb_file).get_residues())\n",
    "    for r in residues:\n",
    "        atoms.append(r['CA'])\n",
    "    ns = NeighborSearch(atoms)\n",
    "    \n",
    "    inter_residues = []\n",
    "    for r in residues:\n",
    "        ca_atom = r['CA']\n",
    "        ca_atom: Atom\n",
    "        neighbors = ns.search(ca_atom.get_vector().get_array(), inter_threshold, \"R\")\n",
    "\n",
    "        other_chain_neighbors = []\n",
    "        for n in neighbors:\n",
    "            if n.get_full_id()[2] != r.get_full_id()[2]:\n",
    "                other_chain_neighbors.append(n)\n",
    "        if len(other_chain_neighbors) >= neighbor_num_threshold:\n",
    "            inter_residues.append(r)\n",
    "    \n",
    "    result = set()\n",
    "    for r in inter_residues:\n",
    "        seq_num = r.get_full_id()[3][1]\n",
    "        posi = seq_num - 1\n",
    "        result.add((uniprot, posi))\n",
    "    return result\n",
    "\n",
    "def get_pred_inter_residues(\n",
    "    df_pred: pd.DataFrame,   \n",
    "    inter_threshold: float = 8.,\n",
    "    neighbor_num_threshold: int = 2,\n",
    "    plddt_threshold: int = 70\n",
    "):\n",
    "    df = df_pred[df_pred['avg_plddt'] >= plddt_threshold]\n",
    "    pred_residues = set()\n",
    "    for _, row in df.iterrows():\n",
    "        pred_residues.add((row['uniprot'], row['resi_seq_posi_1']))\n",
    "        pred_residues.add((row['uniprot'], row['resi_seq_posi_2']))\n",
    "    homomers = set(df['uniprot'])\n",
    "    inter_residues = set()\n",
    "    for uniprot in homomers:\n",
    "        result = get_inter_residues(uniprot, get_homomer_protein(uniprot), inter_threshold, neighbor_num_threshold)\n",
    "        inter_residues |= result\n",
    "    pred_inter_residues = pred_residues & inter_residues\n",
    "    return pred_inter_residues\n",
    "\n",
    "\n",
    "def calc_metrics(\n",
    "    true_residues: set,\n",
    "    pred_residues: set,\n",
    "):\n",
    "    result = dict()\n",
    "    intersection = true_residues & pred_residues\n",
    "    recall = len(intersection) / len(true_residues) if len(true_residues) != 0 else 0\n",
    "    precision = len(intersection) / len(pred_residues) if len(pred_residues) != 0 else 0\n",
    "    f1 = 2 * recall * precision / (recall + precision) if (recall + precision) != 0 else 0\n",
    "    result['precision'] = precision\n",
    "    result['recall'] = recall\n",
    "    result['f1'] = f1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_inter_residues = set(zip(df_anno_with_homomers['uniprot'], df_anno_with_homomers['resi_domain_posi']))\n",
    "\n",
    "inter_thresholds = [4, 6, 8, 10]\n",
    "neighbor_num_thresholds = [1, 2, 3]\n",
    "plddt_thresholds = [60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "records = []\n",
    "for i, n, p in product(inter_thresholds, neighbor_num_thresholds, plddt_thresholds):\n",
    "    pred_inter_residues = get_pred_inter_residues(df_pred_with_homomers, i, n, p)\n",
    "    record = calc_metrics(anno_inter_residues, pred_inter_residues)\n",
    "    record.update({\n",
    "        \"inter_threshold\": i,\n",
    "        \"neighbor_num_threshold\": n,\n",
    "        \"plddt_threshold\": p\n",
    "    })\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision                  0.500000\n",
       "recall                     0.307692\n",
       "f1                         0.380952\n",
       "inter_threshold            8.000000\n",
       "neighbor_num_threshold     1.000000\n",
       "plddt_threshold           70.000000\n",
       "Name: 25, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(records)\n",
    "df_result.iloc[df_result['f1'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P31415', 127),\n",
       " ('P31415', 134),\n",
       " ('P31415', 258),\n",
       " ('P31415', 260),\n",
       " ('P31415', 263),\n",
       " ('P31415', 329),\n",
       " ('P31415', 330),\n",
       " ('Q08499', 79),\n",
       " ('Q08499', 81),\n",
       " ('Q9NZV8', 104),\n",
       " ('Q9NZV8', 110),\n",
       " ('Q9NZV8', 131),\n",
       " ('Q9NZV8', 132)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{('A2RUC4', 182),\n",
       " ('A2RUC4', 184),\n",
       " ('P04183', 185),\n",
       " ('P35914', 238),\n",
       " ('Q08499', 243),\n",
       " ('Q9NZV8', 104),\n",
       " ('Q9NZV8', 110),\n",
       " ('Q9NZV8', 131),\n",
       " ('Q9NZV8', 132)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_inter_residues\n",
    "get_pred_inter_residues(df_pred_with_homomers, 8, 1, 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
